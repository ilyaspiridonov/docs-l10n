{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Entrada distribuída"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/input\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/input.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/input.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/distribute/input.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "As APIs de [tf.distribute](https://www.tensorflow.org/guide/distributed_training) oferecem uma maneira fácil de os usuários aumentarem a escala do treinamento de uma máquina para várias. Ao aumentar a escala do modelo, os usuários também precisam distribuir a entrada em diversos dispositivos. `tf.distribute` fornece APIs que permitem distribuir automaticamente sua entrada entre os dispositivos.\n",
        "\n",
        "Este guia mostrará as diferentes formas de criar um dataset distribuído e iteradores usando as APIs de `tf.distribute`. Além disso, os seguintes tópicos serão discutidos:\n",
        "\n",
        "- Uso, fragmentação e opções de divisão em lotes ao usar `tf.distribute.Strategy.experimental_distribute_dataset` e `tf.distribute.Strategy.distribute_datasets_from_function`.\n",
        "- Diferentes formas de fazer a iteração do dataset distribuído.\n",
        "- Diferenças entre as APIs `tf.distribute.Strategy.experimental_distribute_dataset`/`tf.distribute.Strategy.distribute_datasets_from_function` e APIs de `tf.data`, bem como qualquer limitação que os usuários poderão ter ao usá-las.\n",
        "\n",
        "Este guia não aborda o uso de entrada distribuída com APIs do Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM6W__qraV55"
      },
      "source": [
        "## Datasets distribuídos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNy9GxjSlMKQ"
      },
      "source": [
        "Para usar APIs de `tf.distribute` para aumentar a escala, use `tf.data.Dataset` para representar a entrada. `tf.distribute` funciona de forma eficiente com `tf.data.Dataset` — por exemplo, pela pré-busca automática no dispositivo acelerador e atualizações de desempenho regulares. Se você tiver um caso de uso que exija a utilização de algo diferente de `tf.data.Dataset`, confira a seção [Entradas de tensor](#tensorinputs) deste guia. Em um loop de treinamento não distribuído, primeiro crie uma instância de `tf.data.Dataset` e depois faça a iteração dos elementos. Por exemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCu2Jj-21AEf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cnilUtmKwpa"
      },
      "outputs": [],
      "source": [
        "# Simulate multiple CPUs with virtual devices\n",
        "N_VIRTUAL_DEVICES = 2\n",
        "physical_devices = tf.config.list_physical_devices(\"CPU\")\n",
        "tf.config.set_logical_device_configuration(\n",
        "    physical_devices[0], [tf.config.LogicalDeviceConfiguration() for _ in range(N_VIRTUAL_DEVICES)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd4l1ySeLRk1"
      },
      "outputs": [],
      "source": [
        "print(\"Available devices:\")\n",
        "for i, device in enumerate(tf.config.list_logical_devices()):\n",
        "  print(\"%d) %s\" % (i, device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 16\n",
        "# Create a tf.data.Dataset object.\n",
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "  features, labels = inputs\n",
        "  return labels - 0.3 * features\n",
        "\n",
        "# Iterate over the dataset using the for..in construct.\n",
        "for inputs in dataset:\n",
        "  print(train_step(inputs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihrhYDYRrVLH"
      },
      "source": [
        "Para permitir que os usuários utilizem a estratégia do `tf.distribute` com mudanças mínimas do código existente, duas APIs foram lançadas, que distribuem uma instância de `tf.data.Dataset` e retornam um objeto do dataset distribuído. Então, um usuário pode fazer a iteração dessa instância do dataset distribuído e treinar o modelo conforme mencionado. Agora, vejamos maiores detalhes das duas APIs – `tf.distribute.Strategy.experimental_distribute_dataset` e `tf.distribute.Strategy.distribute_datasets_from_function`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AXoHhrsbdF3"
      },
      "source": [
        "### `tf.distribute.Strategy.experimental_distribute_dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mVuLZhbem8d"
      },
      "source": [
        "#### Uso\n",
        "\n",
        "Esta API recebe uma instância de `tf.data.Dataset` como entrada e retorna uma instância de `tf.distribute.DistributedDataset`. A divisão em lotes do dataset de entrada deve ser igual ao tamanho global de lote. O tamanho global de lote é o número de amostras que você deseja processar em todos os dispositivos no passo 1. Você pode fazer a iteração desse dataset distribuído com Pythonic ou criar um iterador usando `iter`. O objeto retornado não é uma instância de `tf.data.Dataset` e não é compatível com nenhuma outra API que transforma ou inspeciona o dataset de alguma forma. Essa é a API recomendada se você não quiser fragmentar a entrada em diferentes réplicas de forma específica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2VeZUWUj5S4"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 16\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
        "# Distribute input using the `experimental_distribute_dataset`.\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "# 1 global batch of data fed to the model in 1 step.\n",
        "print(next(iter(dist_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPceDmRht54F"
      },
      "source": [
        "#### Propriedades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qb6nDgxiN_n"
      },
      "source": [
        "##### Divisão em lotes\n",
        "\n",
        "`tf.distribute` recria lotes da instância de `tf.data.Dataset` de entrada com um novo tamanho de lote igual ao tamanho global de lote dividido pelo número de réplicas em sincronia. O número de réplicas em sincronia é igual ao número de dispositivos que participam da redução total de gradiente durante o treinamento. Quando um usuário faz uma chamada a `next` no iterador distribuído, um tamanho de dados do lote por réplica é retornado em cada réplica. A cardinalidade do dataset dividido em lotes sempre será múltiplo do número de réplicas. Veja alguns exemplos:\n",
        "\n",
        "- `tf.data.Dataset.range(6).batch(4, drop_remainder=False)`\n",
        "\n",
        "    - Sem distribuição:\n",
        "\n",
        "        - Lote 1: [0, 1, 2, 3]\n",
        "        - Lote 2: [4, 5]\n",
        "\n",
        "    - Com distribuição em 2 réplicas. O último lote ([4, 5]) é dividido entre 2 réplicas.\n",
        "\n",
        "    - Lote 1:\n",
        "\n",
        "        - Réplica 1: [0, 1]\n",
        "        - Réplica 2: [2, 3]\n",
        "\n",
        "    - Lote 2:\n",
        "\n",
        "        - Réplica 1: [4]\n",
        "        - Réplica 2: [5]\n",
        "\n",
        "- `tf.data.Dataset.range(4).batch(4)`\n",
        "\n",
        "    - Sem distribuição:\n",
        "        - Lote 1: [0, 1, 2, 3]\n",
        "    - Com distribuição em 5 réplicas:\n",
        "        - Lote 1:\n",
        "            - Réplica 1: [0]\n",
        "            - Réplica 2: [1]\n",
        "            - Réplica 3: [2]\n",
        "            - Réplica 4: [3]\n",
        "            - Réplica 5: []\n",
        "\n",
        "- `tf.data.Dataset.range(8).batch(4)`\n",
        "\n",
        "    - Sem distribuição:\n",
        "        - Lote 1: [0, 1, 2, 3]\n",
        "        - Lote 2: [4, 5, 6, 7]\n",
        "    - Com distribuição em 3 réplicas:\n",
        "        - Lote 1:\n",
        "            - Réplica 1: [0, 1]\n",
        "            - Réplica 2: [2, 3]\n",
        "            - Réplica 3: []\n",
        "        - Lote 2:\n",
        "            - Réplica 1: [4, 5]\n",
        "            - Réplica 2: [6, 7]\n",
        "            - Réplica 3: []\n",
        "\n",
        "Observação: os exemplos acima apenas ilustram como um lote global é dividido em diferentes réplicas. Não é recomendável depender dos valores reais que vão para cada réplica, pois eles podem mudar dependendo da implementação.\n",
        "\n",
        "A nova divisão em lotes do dataset tem uma complexidade de espaço que aumenta linearmente com o número de réplicas. Portanto, para o caso de uso de treinamento multiworker, o pipeline de entrada pode se deparar com erros de falta de memória (OOM, na sigla em inglês). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IszBuubdtydp"
      },
      "source": [
        "##### Fragmentação\n",
        "\n",
        "`tf.distribute` também fragmenta automaticamente o dataset de entrada no treinamento multiworker com `MultiWorkerMirroredStrategy` e `TPUStrategy`. Cada dataset é criado no dispositivo com CPU do worker. Com a fragmentação automática de um dataset em um conjunto de workers, é atribuído a cada worker um subconjunto de todo o dataset (se a política `tf.data.experimental.AutoShardPolicy` certa estiver definida). Isso é feito para garantir que, em cada passo, um tamanho global de lote de elementos não sobrepostos do dataset seja processado por cada worker. A fragmentação automática tem opções diferentes, que podem ser especificadas usando-se `tf.data.experimental.DistributeOptions`. É importante salientar que não há fragmentação automática no treinamento multiworker com `ParameterServerStrategy`, e mais informações sobre a criação de datasets com essa estratégia estão disponíveis no [tutorial ParameterServerStrategy](parameter_server_training.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwJtsCQhHK-E"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
        "dataset = dataset.with_options(options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7fj3GskHC8g"
      },
      "source": [
        "Há três opções diferentes que você pode definir para a política `tf.data.experimental.AutoShardPolicy`:\n",
        "\n",
        "- AUTO (automática): esta é a opção padrão, em que será feita uma tentativa de fragmentar por FILE (arquivo). A tentativa de fragmentar por FILE falha se não for detectado um dataset baseado em arquivos. Nesse caso, `tf.distribute` reverterá para a fragmentação por DATA (dados). Se o dataset de entrada for baseado em arquivos, mas o número de arquivos for menor do que o número de workers, será gerado um erro `InvalidArgumentError`. Se isso acontecer, defina a política explicitamente como `AutoShardPolicy.DATA` ou divida a fonte de entrada em arquivos menores de tal forma que o número de arquivos seja maior do que o número de workers.\n",
        "\n",
        "- FILE (arquivo): esta é a opção se você quiser fragmentar os arquivos de entrada em todos os workers. Você deve usar esta opção se o número de arquivos de entrada for muito maior do que o número de workers e se os dados nos arquivos estiverem distribuídos de maneira uniforme. A desvantagem desta opção é ficar com workers ociosos se os dados nos arquivos não estiverem distribuídos de maneira uniforme. Se o número de arquivos for menor do que o número de workers, será gerado um erro `InvalidArgumentError`. Se isso acontecer, defina a política explicitamente como `AutoShardPolicy.DATA`. Por exemplo, vamos distribuir 2 arquivos em 2 workers, com 1 réplica cada. O arquivo 1 contém [0, 1, 2, 3, 4, 5] e o arquivo 2 contém [6, 7, 8, 9, 10, 11]. O número total de réplicas em sincronia será 2, e o tamanho global de lote será 4.\n",
        "\n",
        "    - Worker 0:\n",
        "        - Lote 1 =  Réplica 1: [0, 1]\n",
        "        - Lote 2 =  Réplica 1: [2, 3]\n",
        "        - Lote 3 =  Réplica 1: [4]\n",
        "        - Lote 4 =  Réplica 1: [5]\n",
        "    - Worker 1:\n",
        "        - Lote 1 =  Réplica 2: [6, 7]\n",
        "        - Lote 2 =  Réplica 2: [8, 9]\n",
        "        - Lote 3 =  Réplica 2: [10]\n",
        "        - Lote 4 =  Réplica 2: [11]\n",
        "\n",
        "- DATA (dados): os elementos serão fragmentados em todos os workers. Cada worker lerá todo o dataset e processará somente o fragmento atribuído a ele. Todos os outros fragmentos serão descartados. Geralmente, isso é usado se o número de arquivos de entrada for menor do que o número de workers e se você quiser uma melhor fragmentação de dados em todos os workers. A desvantagem é que todo o dataset será lido em cada worker. Por exemplo, vamos distribuir 1 arquivo em 2 workers. O arquivo 1 contém [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]. O número total de réplicas em sincronia será 2.\n",
        "\n",
        "    - Worker 0:\n",
        "        - Lote 1 =  Réplica 1: [0, 1]\n",
        "        - Lote 2 =  Réplica 1: [4, 5]\n",
        "        - Lote 3 =  Réplica 1: [8, 9]\n",
        "    - Worker 1:\n",
        "        - Lote 1 =  Réplica 2: [2, 3]\n",
        "        - Lote 2 =  Réplica 2: [6, 7]\n",
        "        - Lote 3 =  Réplica 2: [10, 11]\n",
        "\n",
        "- OFF (desativada): se você desativar a fragmentação automática, cada worker processará todos os dados. Por exemplo, vamos distribuir 1 arquivo em 2 workers. O arquivo 1 contém [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]. O número total de réplicas em sincronia será 2. Então, cada worker verá a seguinte distribuição:\n",
        "\n",
        "    - Worker 0:\n",
        "\n",
        "        - Lote 1 =  Réplica 1: [0, 1]\n",
        "        - Lote 2 =  Réplica 1: [2, 3]\n",
        "        - Lote 3 =  Réplica 1: [4, 5]\n",
        "        - Lote 4 =  Réplica 1: [6, 7]\n",
        "        - Lote 5 = Réplica 1: [8, 9]\n",
        "        - Lote 6 = Réplica 1: [10, 11]\n",
        "\n",
        "    - Worker 1:\n",
        "\n",
        "        - Lote 1 =  Réplica 2: [0, 1]\n",
        "        - Lote 2 =  Réplica 2: [2, 3]\n",
        "        - Lote 3 =  Réplica 2: [4, 5]\n",
        "        - Lote 4 =  Réplica 2: [6, 7]\n",
        "        - Lote 5 =  Réplica 2: [8, 9]\n",
        "        - Lote 6 = Réplica 2: [10, 11] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK46ZJGPH5H2"
      },
      "source": [
        "##### Pré-busca\n",
        "\n",
        "Por padrão, `tf.distribute` adiciona uma transformação de pré-busca ao final da instância de `tf.data.Dataset` fornecida pelo usuário. O argumento da transformação de pré-busca, que é `buffer_size`, é igual ao número de réplicas em sincronia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjiGSY3gtr6_"
      },
      "source": [
        "### `tf.distribute.Strategy.distribute_datasets_from_function`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAXAo_wWbWSb"
      },
      "source": [
        "#### Uso\n",
        "\n",
        "Esta API recebe uma função de entrada e devolve uma instância de `tf.distribute.DistributedDataset`. A função de entrada que o usuário passa tem um argumento `tf.distribute.InputContext` e deve retornar uma instância de `tf.data.Dataset`. Com esta API, `tf.distribute` não faz nenhuma outra mudança na instância de `tf.data.Dataset` do usuário retornada pela função de entrada. É responsabilidade do usuário criar os lotes e fragmentar o dataset. `tf.distribute` faz uma chamada à função de entrada no dispositivo com CPU de cada worker. Além de permitir que os usuários especifiquem sua própria lógica de divisão lotes e fragmentação, esta API também apresenta escalabilidade e desempenho melhores em comparação a `tf.distribute.Strategy.experimental_distribute_dataset` quando usada para treinamento multiworker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def dataset_fn(input_context):\n",
        "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
        "  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
        "  dataset = dataset.shard(\n",
        "      input_context.num_input_pipelines, input_context.input_pipeline_id)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(2)  # This prefetches 2 batches per device.\n",
        "  return dataset\n",
        "\n",
        "dist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1bpzPYzt_R7"
      },
      "source": [
        "#### Propriedades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cgzhwiiuBvO"
      },
      "source": [
        "##### Divisão em lotes\n",
        "\n",
        "A instância `tf.data.Dataset`, que é o valor de retorno da função de entrada, deve ser dividida em lotes usando o tamanho de lote por réplica. O tamanho de lote por réplica é igual ao tamanho global de lote dividido pelo número de réplicas que fazem parte do treinamento sincronizado. Isso ocorre pelo fato de `tf.distribute` fazer uma chamada à função de entrada no dispositivo com CPU de cada worker. O dataset criado em um determinado worker deve estar pronto para uso por todas as réplicas nesse worker. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-wlFFZbP33n"
      },
      "source": [
        "##### Fragmentação\n",
        "\n",
        "O objeto `tf.distribute.InputContext` que é passado implicitamente como argumento para a função de entrada do usuário é criado por `tf.distribute` em segundo plano. Ele tem informações sobre o número de workers, ID do worker atual, etc. A função de entrada pode realizar a fragmentação conforme as políticas definidas pelo usuário utilizando essas propriedades, que fazem parte do objeto `tf.distribute.InputContext`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TGwnDM-ICHf"
      },
      "source": [
        "##### Pré-busca\n",
        "\n",
        "`tf.distribute` não adiciona uma transformação de pré-busca ao final do `tf.data.Dataset` retornado pela função de entrada fornecida pelo usuário, então você deve fazer uma chamada explicita a `Dataset.prefetch` no exemplo acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOMsf8kyZZpv"
      },
      "source": [
        "Observação: tanto `tf.distribute.Strategy.experimental_distribute_dataset` quanto `tf.distribute.Strategy.distribute_datasets_from_function` retornam instâncias de **`tf.distribute.DistributedDataset` que não são do tipo `tf.data.Dataset`**. Você pode fazer a iteração dessas instâncias (conforme exibido na seção Iteradores distribuídos) e usar a propriedade `element_spec`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL3XbI1gzEjO"
      },
      "source": [
        "## Iteradores distribuídos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8y54-o9T2Ni"
      },
      "source": [
        "De forma similar às instâncias de `tf.data.Dataset` não distribuídas, você precisará criar um iterador nas instâncias de `tf.distribute.DistributedDataset` para fazer a iteração e acessar os elementos em `tf.distribute.DistributedDataset`. Veja abaixo de que maneira você pode criar um `tf.distribute.DistributedIterator` e usá-lo para treinar seu modelo:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlKh8NV0uOtZ"
      },
      "source": [
        "### Usos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSZz6EqOuSlB"
      },
      "source": [
        "#### Uso de um Pythonic para constructo de loop\n",
        "\n",
        "Você pode usar um loop Pythonic amigável para o usuário para fazer a iteração do `tf.distribute.DistributedDataset`. Os elementos retornados pelo `tf.distribute.DistributedIterator` podem ser um único `tf.Tensor` ou um `tf.distribute.DistributedValues`, que contém um valor por réplica. Ao colocar o loop dentro de uma `tf.function`, o desempenho aumenta. Entretanto, os comandos `break` e `return` não estarão disponíveis para um loop de um `tf.distribute.DistributedDataset` que é colocado dentro de uma `tf.function`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt3AHb46Tr3w"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 16\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs):\n",
        "  features, labels = inputs\n",
        "  return labels - 0.3 * features\n",
        "\n",
        "for x in dist_dataset:\n",
        "  # train_step trains the model using the dataset elements\n",
        "  loss = mirrored_strategy.run(train_step, args=(x,))\n",
        "  print(\"Loss is \", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NchPwTEiuSqb"
      },
      "source": [
        "#### Uso de `iter` para criar um iterador explícito\n",
        "\n",
        "Para fazer a iteração dos elementos em uma instância de `tf.distribute.DistributedDataset`, você pode criar um `tf.distribute.DistributedIterator` usando a API `iter` nele. Com um iterador explícito, você pode fazer a iteração em um número fixo de passos. Para obter o próximo elemento do `dist_iterator` de uma instância de `tf.distribute.DistributedIterator`, você pode fazer uma chamada a `next(dist_iterator)`, `dist_iterator.get_next()` ou `dist_iterator.get_next_as_optional()`. Os dois últimos são basicamente a mesma coisa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrMmakq5EqeQ"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "steps_per_epoch = 5\n",
        "for epoch in range(num_epochs):\n",
        "  dist_iterator = iter(dist_dataset)\n",
        "  for step in range(steps_per_epoch):\n",
        "    # train_step trains the model using the dataset elements\n",
        "    loss = mirrored_strategy.run(train_step, args=(next(dist_iterator),))\n",
        "    # which is the same as\n",
        "    # loss = mirrored_strategy.run(train_step, args=(dist_iterator.get_next(),))\n",
        "    print(\"Loss is \", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpJXIlxjqPYg"
      },
      "source": [
        "Com `next` ou `tf.distribute.DistributedIterator.get_next`, se o `tf.distribute.DistributedIterator` tiver chegado ao fim, será exibido um erro OutOfRange (fora do intervalo). O cliente pode capturar o erro no Python e continuar fazendo outros trabalhos, como criação de checkpoints e avaliação. Entretanto, isso não funcionará se você estiver usando um loop de treinamento de host (por exemplo, executando diversos passos por `tf.function)`, desta forma:\n",
        "\n",
        "```\n",
        "@tf.function\n",
        "def train_fn(iterator):\n",
        "  for _ in tf.range(steps_per_loop):\n",
        "    strategy.run(step_fn, args=(next(iterator),))\n",
        "```\n",
        "\n",
        "Este exemplo `train_fn` contém diversos passos com o encapsulamento do corpo do passo dentro de um `tf.range`. Neste caso, iterações diferentes no loop sem nenhuma dependência poderiam começar em paralelo, então um erro OutOfRange pode ser gerado em iterações posteriores, antes de a computação de iterações anteriores terminar. Quando um erro OutOfRange é gerado, todas as operações da função são encerradas imediatamente. Se você deseja evitar esse tipo de situação, uma alternativa que não gera um erro OutOfRange é `tf.distribute.DistributedIterator.get_next_as_optional`. `get_next_as_optional` retorna um `tf.experimental.Optional`, que contém o próximo elemento ou nenhum valor se `tf.distribute.DistributedIterator` tiver chegado ao fim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iyjao96Vqwyz"
      },
      "outputs": [],
      "source": [
        "# You can break the loop with `get_next_as_optional` by checking if the `Optional` contains a value\n",
        "global_batch_size = 4\n",
        "steps_per_loop = 5\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.range(9).batch(global_batch_size)\n",
        "distributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))\n",
        "\n",
        "@tf.function\n",
        "def train_fn(distributed_iterator):\n",
        "  for _ in tf.range(steps_per_loop):\n",
        "    optional_data = distributed_iterator.get_next_as_optional()\n",
        "    if not optional_data.has_value():\n",
        "      break\n",
        "    per_replica_results = strategy.run(lambda x: x, args=(optional_data.get_value(),))\n",
        "    tf.print(strategy.experimental_local_results(per_replica_results))\n",
        "train_fn(distributed_iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaclbKnqzLjf"
      },
      "source": [
        "## Uso da propriedade `element_spec`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1YvXqOpwy08"
      },
      "source": [
        "Se você passar os elementos de um dataset distribuído para uma `tf.function` e quiser um `tf.TypeSpec` garantido, pode especificar o argumento `input_signature` da `tf.function`. A saída de um dataset distribuído é `tf.distribute.DistributedValues`, que pode representar a entrada de um único dispositivo ou de vários. Para obter o `tf.TypeSpec` correspondente a esse valor distribuído, você pode usar `tf.distribute.DistributedDataset.element_spec` ou `tf.distribute.DistributedIterator.element_spec`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg3B-Cw_cn3a"
      },
      "outputs": [],
      "source": [
        "global_batch_size = 16\n",
        "epochs = 5\n",
        "steps_per_epoch = 5\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "@tf.function(input_signature=[dist_dataset.element_spec])\n",
        "def train_step(per_replica_inputs):\n",
        "  def step_fn(inputs):\n",
        "    return 2 * inputs\n",
        "\n",
        "  return mirrored_strategy.run(step_fn, args=(per_replica_inputs,))\n",
        "\n",
        "for _ in range(epochs):\n",
        "  iterator = iter(dist_dataset)\n",
        "  for _ in range(steps_per_epoch):\n",
        "    output = train_step(next(iterator))\n",
        "    tf.print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OAa6svUzuWm"
      },
      "source": [
        "## Pré-processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSMrs3kJQexW"
      },
      "source": [
        "Até agora, você aprendeu como distribuir um `tf.data.Dataset`. Porém, antes que os dados estejam prontos para o modelo, eles precisam ser pré-processados para limpeza, transformação ou aumento, por exemplo. Veja dois conjuntos de ferramentas úteis:\n",
        "\n",
        "-     [Camadas de pré-processamento do Keras](https://www.tensorflow.org/guide/keras/preprocessing_layers): conjunto de camadas do Keras que permitem aos desenvolvedores criar pipelines de processamento de entrada nativos do Keras. Algumas camadas de pré-processamento do Keras contêm estados não treináveis, que podem ser definidos na inicialização ou `adapt`ados (consulte a seção `adaptar` do [guia de camadas de pré-processamento do Keras](https://www.tensorflow.org/guide/keras/preprocessing_layers)). Ao distribuir camadas de pré-processamento stateful, os estados devem ser replicados em todos os workers. Para usar essas camadas, você pode torná-las parte do modelo ou aplicá-las aos datasets.\n",
        "\n",
        "- [TensorFlow Transform (tf.Transform)](https://www.tensorflow.org/tfx/transform/get_started): biblioteca do TensorFlow que permite definir uma transformação de dados tanto no nível de instância quanto de passos completos por meio de pipelines de pré-processamento de dados. O TensorFlow Transform tem duas fases. A primeira é a fase Analisar, em que os dados de treinamento não tratados são analisados em um processo de passos completos para computar as estatísticas necessárias para as transformações, e a lógica de transformação é gerada como operações no nível de instância. A segunda é a fase Transformar, em que os dados de treinamento não tratados são transformados em um processo no nível de instância.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd4aUCFdVlZ1"
      },
      "source": [
        "### Camadas de pré-processamento do Keras versus TensorFlow Transform\n",
        "\n",
        "Tanto o TensorFlow Transform quanto as camadas de pré-processamento do Keras oferecem uma maneira de dividir o pré-processamento durante o treinamento e agrupar o pré-processamento com um modelo durante a inferência, reduzindo o desvio de treinamento/exibição.\n",
        "\n",
        "O TensorFlow Transform, que está intimamente integrado ao [TFX](https://www.tensorflow.org/tfx), oferece uma solução map-reduce escalável para analisar e transformar datasets de qualquer tamanho em um trabalho separado do pipeline de treinamento. Se você precisar fazer uma análise de um dataset que não caiba em uma única máquina, o TensorFlow Transform deve ser sua primeira opção.\n",
        "\n",
        "As camadas de pré-processamento do Keras são mais adequadas para pré-processamento aplicado durante o treinamento, após ler os dados no disco. Elas são perfeitamente adequadas para o desenvolvimento de modelos na biblioteca do Keras. Elas permitem a análise de um dataset menor com o uso de [`adapt`](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method) e possibilitam também casos de uso como ampliação de dados de imagens, em que cada passo do dataset de entrada gera exemplos diferentes para o treinamento.\n",
        "\n",
        "As duas bibliotecas podem ser combinadas, em que o TensorFlow Transform é usado para análise e transformações estáticas dos dados de entrada, e as camadas de pré-processamento do Keras são usadas para transformações de treinamento-tempo (por exemplo, one-hot encoding ou ampliação de dados).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MReKhhZpHUpj"
      },
      "source": [
        "### Melhores práticas com tf.distribute\n",
        "\n",
        "Para trabalhar com as duas ferramentas, é preciso inicializar a lógica de transformação para aplicar aos dados, o que pode criar recursos do Tensorflow. Esses recursos ou estados devem ser replicados em todos os workers para salvar a comunicação inter-worker ou worker-coordenador. Para isso, recomenda-se que você crie camadas de pré-processamento do Keras, `tft.TFTransformOutput.transform_features_layer`, ou `tft.TransformFeaturesLayer` em `tf.distribute.Strategy.scope`, da mesma forma que faria para qualquer outra camada do Keras.\n",
        "\n",
        "Os próximos exemplos demonstram o uso da API `tf.distribute.Strategy` com a API de alto nível do Keras, `Model.fit`, e um loop de treinamento personalizado separadamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwEGMWuoX7kJ"
      },
      "source": [
        "#### Observações adicionais para usuários de camadas de pré-processamento do Keras:\n",
        "\n",
        "**Pré-processamento de camadas e vocabulários grandes**\n",
        "\n",
        "Ao lidar com vocabulários grandes (mais de 1 GB) em uma configuração multiworker (por exemplo, `tf.distribute.MultiWorkerMirroredStrategy`, `tf.distribute.experimental.ParameterServerStrategy`, `tf.distribute.TPUStrategy`), recomenda-se salvar o vocabulário em um arquivo estático acessível por todos os workers (por exemplo, com armazenamento em nuvem). Dessa forma, será reduzido o tempo gasto ao replicar o vocabulário em todos os workers durante o treinamento.\n",
        "\n",
        "**Pré-processamento no pipeline de `tf.data` versus no modelo**\n",
        "\n",
        "Embora as camadas de pré-processamento do Keras possam ser aplicadas tanto como parte do modelo quanto diretamente a um `tf.data.Dataset`, cada opção tem sua vantagem:\n",
        "\n",
        "- Ao aplicar as camadas de pré-processamento no modelo, o seu modelo fica mais portátil, e isso ajuda a reduzir o desvio de treinamento/exibição. (Confira mais detalhes na seção *Benefícios de fazer o pré-processamento dentro do modelo no momento da inferência* do [guia Trabalhando com camadas de pré-processamento](https://www.tensorflow.org/guide/keras/preprocessing_layers#benefits_of_doing_preprocessing_inside_the_model_at_inference_time))\n",
        "- Ao aplicar no pipeline de `tf.data`, é possível fazer a pré-busca e o descarregamento na CPU, o que costuma oferecer melhor desempenho ao usar aceleradores.\n",
        "\n",
        "Ao executar em uma ou mais TPUs, os usuários devem quase sempre colocar as camadas de pré-processamento do Keras no pipeline de `tf.data`, pois nem todas as camadas têm suporte a TPUs, e operações com strings não são executadas em TPUs. (As duas exceções são `tf.keras.layers.Normalization` e `tf.keras.layers.Rescaling`, que são executadas sem problemas em TPUs e usadas com frequência como a primeira camada em um modelo de imagens.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNCYZ9L-BD2R"
      },
      "source": [
        "### Pré-processamento com `Model.fit`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhRB2Xe8B6bX"
      },
      "source": [
        "Ao usar o `Model.fit` do Keras, você não precisa distribuir dados com `tf.distribute.Strategy.experimental_distribute_dataset` nem `tf.distribute.Strategy.distribute_datasets_from_function`. Confira mais detalhes no [guia Trabalhando com camadas de pré-processamento](https://www.tensorflow.org/guide/keras/preprocessing_layers) e no [guia Treinamento distribuído com o Keras](https://www.tensorflow.org/tutorials/distribute/keras). Veja um exemplo resumido abaixo:\n",
        "\n",
        "```\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "with strategy.scope():\n",
        "  # Create the layer(s) under scope.\n",
        "  integer_preprocessing_layer = tf.keras.layers.IntegerLookup(vocabulary=FILE_PATH)\n",
        "  model = ...\n",
        "  model.compile(...)\n",
        "dataset = dataset.map(lambda x, y: (integer_preprocessing_layer(x), y))\n",
        "model.fit(dataset)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zL2vzJ-G0yg"
      },
      "source": [
        "Usuários de `tf.distribute.experimental.ParameterServerStrategy` com a API `Model.fit` precisam usar um `tf.keras.utils.experimental.DatasetCreator` como a entrada. (Confira mais detalhes no guia [Treinamento de servidor de parâmetros](https://www.tensorflow.org/tutorials/distribute/parameter_server_training#parameter_server_training_with_modelfit_api))\n",
        "\n",
        "```\n",
        "strategy = tf.distribute.experimental.ParameterServerStrategy(\n",
        "    cluster_resolver,\n",
        "    variable_partitioner=variable_partitioner)\n",
        "\n",
        "with strategy.scope():\n",
        "  preprocessing_layer = tf.keras.layers.StringLookup(vocabulary=FILE_PATH)\n",
        "  model = ...\n",
        "  model.compile(...)\n",
        "\n",
        "def dataset_fn(input_context):\n",
        "  ...\n",
        "  dataset = dataset.map(preprocessing_layer)\n",
        "  ...\n",
        "  return dataset\n",
        "\n",
        "dataset_creator = tf.keras.utils.experimental.DatasetCreator(dataset_fn)\n",
        "model.fit(dataset_creator, epochs=5, steps_per_epoch=20, callbacks=callbacks)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imZLQUOYBJyW"
      },
      "source": [
        "### Pré-processamento com um loop de treinamento personalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2PX1QH_OwU3"
      },
      "source": [
        "Ao escrever um [loop de treinamento personalizado](https://www.tensorflow.org/tutorials/distribute/custom_training), você distribuirá os dados com a API `tf.distribute.Strategy.experimental_distribute_dataset` ou com a API `tf.distribute.Strategy.distribute_datasets_from_function`. Se você distribuir o dataset por meio de `tf.distribute.Strategy.experimental_distribute_dataset`, a aplicação dessas APIs de pré-processamento em seu pipeline de dados deixará automaticamente os recursos co-localizados com o pipeline de dados, evitando acesso remoto aos recursos. Portanto, todos os nossos exemplos usarão `tf.distribute.Strategy.distribute_datasets_from_function` e, neste caso, é essencial colocar a inicialização dessas APIs em `strategy.scope()` para maior eficiência:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJS1UmcWQeab"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "vocab = [\"a\", \"b\", \"c\", \"d\", \"f\"]\n",
        "\n",
        "with strategy.scope():\n",
        "  # Create the layer(s) under scope.\n",
        "  layer = tf.keras.layers.StringLookup(vocabulary=vocab)\n",
        "\n",
        "def dataset_fn(input_context):\n",
        "  # a tf.data.Dataset\n",
        "  dataset = tf.data.Dataset.from_tensor_slices([\"a\", \"c\", \"e\"]).repeat()\n",
        "\n",
        "  # Custom your batching, sharding, prefetching, etc.\n",
        "  global_batch_size = 4\n",
        "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.shard(\n",
        "      input_context.num_input_pipelines,\n",
        "      input_context.input_pipeline_id)\n",
        "\n",
        "  # Apply the preprocessing layer(s) to the tf.data.Dataset\n",
        "  def preprocess_with_kpl(input):\n",
        "    return layer(input)\n",
        "\n",
        "  processed_ds = dataset.map(preprocess_with_kpl)\n",
        "  return processed_ds\n",
        "\n",
        "distributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n",
        "\n",
        "# Print out a few example batches.\n",
        "distributed_dataset_iterator = iter(distributed_dataset)\n",
        "for _ in range(3):\n",
        "  print(next(distributed_dataset_iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVl1cblWQy8b"
      },
      "source": [
        "É importante salientar que, se você estiver fazendo o treinamento com `tf.distribute.experimental.ParameterServerStrategy`, também fará uma chamada a `tf.distribute.experimental.coordinator.ClusterCoordinator.create_per_worker_dataset`\n",
        "\n",
        "```\n",
        "@tf.function\n",
        "def per_worker_dataset_fn():\n",
        "  return strategy.distribute_datasets_from_function(dataset_fn)\n",
        "\n",
        "per_worker_dataset = coordinator.create_per_worker_dataset(per_worker_dataset_fn)\n",
        "per_worker_iterator = iter(per_worker_dataset)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol7SmPID1dAt"
      },
      "source": [
        "Para o TensorFlow Transform, conforme mencionado acima, a fase Analisar é feita separadamente do treinamento e, portanto, foi omitida aqui. Confira as instruções detalhadas no [tutorial](https://www.tensorflow.org/tfx/tutorials/transform/census). Geralmente, essa fase inclui a criação de uma função de pré-processamento `tf.Transform` e a transformação dos dados em um pipeline do [Apache Beam](https://beam.apache.org/) com essa função de pré-processamento. No final da fase Analisar, a saída pode ser exportada como um grafo do Tensorflow, que você pode usar tanto para treinamento quanto para produção. Nosso exemplo abrange somente a parte do pipeline de treinamento:\n",
        "\n",
        "```\n",
        "with strategy.scope():\n",
        "  # working_dir contains the tf.Transform output.\n",
        "  tf_transform_output = tft.TFTransformOutput(working_dir)\n",
        "  # Loading from working_dir to create a Keras layer for applying the tf.Transform output to data\n",
        "  tft_layer = tf_transform_output.transform_features_layer()\n",
        "  ...\n",
        "\n",
        "def dataset_fn(input_context):\n",
        "  ...\n",
        "  dataset.map(tft_layer, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  ...\n",
        "  return dataset\n",
        "\n",
        "distributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_IQxRXxQWof"
      },
      "source": [
        "## Lotes parciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW2_gVkiztUG"
      },
      "source": [
        "Os lotes parciais são encontrados: 1) Quando instâncias do `tf.data.Dataset` criadas pelos usuários podem conter tamanhos de lote que não geram um número inteiro ao serem divididos pelo número de réplicas; ou 2) quando a cardinalidade da instância do dataset não é divisível pelo tamanho do lote. Portanto, quando o dataset é distribuído em várias réplicas, a chamada `next` em alguns iteradores pode resultar em um erro `tf.errors.OutOfRangeError`. Para tratar esse caso de uso, `tf.distribute` retorna lotes simulados com tamanho de lote igual a `0` para as réplicas que não têm mais dados a processar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqutdpqtPcCH"
      },
      "source": [
        "Para o caso com um único worker, se os dados não forem retornados pela chamada `next` no iterador, lotes simulados de tamanho de lote igual a 0 serão criados e usados junto com os dados reais no dataset. No caso de lotes parciais, o último lote global de dados conterá dados reais junto com lotes simulados de dados. Agora, a condição de parada dos dados de processamento verifica se alguma das réplicas tem dados. Se não houver dados em nenhuma das réplicas, será gerado um erro `tf.errors.OutOfRangeError`.\n",
        "\n",
        "Para o caso multiworker, o valor booleano que representa a presença de dados em cada um dos workers é agregado usando a comunicação entre réplicas, e ele é usado para identificar se todos os workers terminaram o processamento do dataset distribuído. Como isso envolve comunicação entre workers, há uma certa perda de desempenho.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vehLsgljz90Y"
      },
      "source": [
        "## Ressalvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx4jyN_Az-Dy"
      },
      "source": [
        "- Ao usar as APIs `tf.distribute.Strategy.experimental_distribute_dataset` em uma configuração multiworker, você passa um `tf.data.Dataset` que lê os arquivos. Se a política `tf.data.experimental.AutoShardPolicy` estiver definida como `AUTO` (automática) ou `FILE` (arquivo), o tamanho real do lote por passo pode ser menor do que aquele que você definiu como o tamanho global de lote. Isso pode acontecer quando os elementos restantes no arquivo são menores do que o tamanho global de lote. Você pode esgotar o dataset sem depender do número de passos a serem executados ou, alternativamente, definir `tf.data.experimental.AutoShardPolicy` como `DATA` (dados).\n",
        "\n",
        "- Atualmente, não há suporte a transformações do dataset stateful usando o `tf.distribute`, e qualquer operação stateful que o dataset possa ter é ignorada. Por exemplo, se o seu dataset tiver um `map_fn` que use `tf.random.uniform` para girar uma imagem, então você tem um grafo de dataset que depende de estados (ou seja, a semente aleatória) na máquina local na qual o processo Python está sendo executado.\n",
        "\n",
        "- Opções `tf.data.experimental.OptimizationOptions` experimentais que são desativadas por padrão podem causar uma degradação de desempenho em determinados contextos (como quando usadas em conjunto com `tf.distribute`). Você pode ativá-las somente após validar que elas aumentam o desempenho para sua carga de trabalho em uma configuração distribuída.\n",
        "\n",
        "- Confira [este guia](https://www.tensorflow.org/guide/data_performance) para ver como otimizar seu pipeline de entrada com o `tf.data`, de forma geral. Algumas dicas adicionais:\n",
        "\n",
        "    - Se você tiver vários workers e estiver usando `tf.data.Dataset.list_files` para criar um dataset com todos os arquivos que correspondam a um ou mais padrões glob, lembre-se de definir o argumento `seed` ou definir `shuffle=False` para que cada worker fragmente o arquivo de forma consistente.\n",
        "\n",
        "- Caso o seu pipeline de entrada inclua tanto a mistura de dados no nível de registro quanto o processamento de dados, a menos que os dados não processados sejam consideravelmente maiores do que os dados processados (o que não costuma ser o caso), misture os dados primeiro e depois faça o processamento, conforme exibido no exemplo abaixo. Isso pode trazer benefícios para o uso de memória e o desempenho.\n",
        "\n",
        "```\n",
        "d = tf.data.Dataset.list_files(pattern, shuffle=False)\n",
        "d = d.shard(num_workers, worker_index)\n",
        "d = d.repeat(num_epochs)\n",
        "d = d.shuffle(shuffle_buffer_size)\n",
        "d = d.interleave(tf.data.TFRecordDataset,\n",
        "                 cycle_length=num_readers, block_length=1)\n",
        "d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
        "```\n",
        "\n",
        "- `tf.data.Dataset.shuffle(buffer_size, seed=None, reshuffle_each_iteration=None)` mantém um buffer interno de elementos `buffer_size` e, portanto, reduzir o `buffer_size` pode mitigar o problema de falta de memória (OOM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAC_vRmJyzrB"
      },
      "source": [
        "- A ordem de processamento dos dados pelos workers ao usar `tf.distribute.experimental_distribute_dataset` ou `tf.distribute.distribute_datasets_from_function` não é garantida. Geralmente, isso é necessário se você estiver usando `tf.distribute` para aumentar a escala da previsão. Entretanto, você pode inserir um índice para cada elemento do lote e ordenar as saídas. O trecho de código abaixo é um exemplo de como ordenar saídas.\n",
        "\n",
        "Observação: `tf.distribute.MirroredStrategy` é usado aqui apenas por conveniência. Você só precisa reordenar as entradas ao usar diversos workers, mas `tf.distribute.MirroredStrategy` é usada para distribuir o treinamento em um único worker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr2xAy-uZZaL"
      },
      "outputs": [],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "dataset_size = 24\n",
        "batch_size = 6\n",
        "dataset = tf.data.Dataset.range(dataset_size).enumerate().batch(batch_size)\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "def predict(index, inputs):\n",
        "  outputs = 2 * inputs\n",
        "  return index, outputs\n",
        "\n",
        "result = {}\n",
        "for index, inputs in dist_dataset:\n",
        "  output_index, outputs = mirrored_strategy.run(predict, args=(index, inputs))\n",
        "  indices = list(mirrored_strategy.experimental_local_results(output_index))\n",
        "  rindices = []\n",
        "  for a in indices:\n",
        "    rindices.extend(a.numpy())\n",
        "  outputs = list(mirrored_strategy.experimental_local_results(outputs))\n",
        "  routputs = []\n",
        "  for a in outputs:\n",
        "    routputs.extend(a.numpy())\n",
        "  for i, value in zip(rindices, routputs):\n",
        "    result[i] = value\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbn7HXx0YqB"
      },
      "source": [
        "<a name=\"tensorinputs\"> ## Entradas de tensor em vez de tf.data </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dymZixqo0nKK"
      },
      "source": [
        "Às vezes, os usuários não podem usar um `tf.data.Dataset` para representar a entrada e, consequentemente, as APIs mencionadas acima para distribuir o dataset em diversos dispositivos. Nesses casos, você pode usar tensores brutos ou entradas de um gerador.\n",
        "\n",
        "### Uso de experimental_distribute_values_from_function para entradas de tensor arbitrárias\n",
        "\n",
        "`strategy.run` aceita `tf.distribute.DistributedValues`, que é a saída de `next(iterator)`. Para passar os valores dos tensores, use `tf.distribute.Strategy.experimental_distribute_values_from_function` para construir `tf.distribute.DistributedValues` a partir de tensores brutos. Com essa opção, o usuário precisará especificar sua própria lógica de divisão em lotes e fragmentação na função de entrada, o que pode ser feito usando o objeto de entrada `tf.distribute.experimental.ValueContext`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajZHNRQs0kqm"
      },
      "outputs": [],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def value_fn(ctx):\n",
        "  return tf.constant(ctx.replica_id_in_sync_group)\n",
        "\n",
        "distributed_values = mirrored_strategy.experimental_distribute_values_from_function(value_fn)\n",
        "for _ in range(4):\n",
        "  result = mirrored_strategy.run(lambda x: x, args=(distributed_values,))\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P98aFQGf0x_7"
      },
      "source": [
        "### Uso de tf.data.Dataset.from_generator se a sua entrada for a partir de um gerador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emZCWQSi04qT"
      },
      "source": [
        "Se você tiver uma função geradora que queira usar, pode criar uma instância de `tf.data.Dataset` usando a API `from_generator`.\n",
        "\n",
        "Observação: no momento, isso não é compatível com `tf.distribute.TPUStrategy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRhU0X230787"
      },
      "outputs": [],
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "def input_gen():\n",
        "  while True:\n",
        "    yield np.random.rand(4)\n",
        "\n",
        "# use Dataset.from_generator\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    input_gen, output_types=(tf.float32), output_shapes=tf.TensorShape([4]))\n",
        "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
        "iterator = iter(dist_dataset)\n",
        "for _ in range(4):\n",
        "  result = mirrored_strategy.run(lambda x: x, args=(next(iterator),))\n",
        "  print(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "input.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
