{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT-LkFOl2axM"
      },
      "source": [
        "# Uso de DTensors com o Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/distribute/dtensor_keras_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTe9dcbUAwqx"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "Neste tutorial, você aprenderá a usar o DTensor com o Keras.\n",
        "\n",
        "Por meio da integração do DTensor com o Keras, você pode reutilizar suas camadas e modelos atuais do Keras para criar e treinar modelos de aprendizado de máquina distribuídos.\n",
        "\n",
        "Você treinará um modelo de classificação multicamada com os dados MNIST. Será demonstrado como definir o layout do modelo de subclasse, o modelo sequencial e o modelo funcional.\n",
        "\n",
        "Para este tutorial, pressupõe-se que você já tenha lido o [guia de programação do DTensor](/guide/dtensor_overview) e conheça os conceitos básicos do DTensor, como `Mesh` e `Layout`.\n",
        "\n",
        "Este tutorial é baseado em https://www.tensorflow.org/datasets/keras_example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keIyP3IoA1o4"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "O DTensor faz parte da versão 2.9.0 do TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dHik7NYA5vm"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade --pre tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VttBMZngDx8x"
      },
      "source": [
        "Em seguida, importe `tensorflow` e `tensorflow.experimental.dtensor`, e configure o TensorFlow para usar 8 CPUs virtuais.\n",
        "\n",
        "Embora este exemplo use CPUs, o DTensor funciona da mesma forma em dispositivos com CPU, GPU ou TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CodX6idGBGSm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.experimental import dtensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAtvrpasDpDD"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(\n",
        "        phy_devices[0], \n",
        "        [tf.config.LogicalDeviceConfiguration()] * ncpu)\n",
        "  \n",
        "configure_virtual_cpus(8)\n",
        "tf.config.list_logical_devices('CPU')\n",
        "\n",
        "devices = [f'CPU:{i}' for i in range(8)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogULE1OHtyd9"
      },
      "source": [
        "## Geradores de números pseudoaleatórios determinísticos\n",
        "\n",
        "É importante salientar que a API do DTensor requer que todos os clientes em execução tenham as mesmas sementes aleatórias para que o comportamento de inicialização dos pesos seja determinístico. Para conseguir isso, basta definir as sementes globais no Keras pela função `tf.keras.utils.set_random_seed()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u85YypguL8N"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.experimental.enable_tf_random_generator()\n",
        "tf.keras.utils.set_random_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO11XvPDAu3_"
      },
      "source": [
        "## Criação de uma malha para paralelismo de dados\n",
        "\n",
        "Este tutorial demonstra o treinamento Paralelo de Dados. A adaptação para os treinamentos Paralelo de Modelos e Paralelo Espacial pode ser tão simples quanto alterar para um conjunto diferente de objetos `Layout`. Confira o [tutorial aprofundado do DTensor sobre aprendizado de máquina](https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial) para ver mais informações sobre outros treinamentos distribuídos além do Paralelo de Dados.\n",
        "\n",
        "O treinamento Paralelo de Dados é um esquema de treinamento paralelo usando com frequência, também utilizado, por exemplo, em `tf.distribute.MirroredStrategy`.\n",
        "\n",
        "Com o DTensor, um loop de treinamento Paralelo de Dados usa uma `Mesh` que consiste de uma única dimensão de “lote”, em que cada dispositivo executa uma réplica do modelo, que recebe um fragmento do lote global.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sT6s6z4j9H-"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=devices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rouFcF6FE0aF"
      },
      "source": [
        "Como cada dispositivo executa uma réplica completa do modelo, as variáveis ​​do modelo devem ser totalmente replicadas na malha (sem fragmentação). Por exemplo, um Layout totalmente replicado para um peso de posto 2 nesta `Mesh` seria o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8OxvkDKE1Nu"
      },
      "outputs": [],
      "source": [
        "example_weight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)  # or\n",
        "example_weight_layout = dtensor.Layout.replicated(mesh, rank=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bnic98RE0xi"
      },
      "source": [
        "Um layout de um tensor de dados posto 2 nesta `Mesh` seria fragmentado na primeira dimensão (conhecida também como `batch_sharded`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhYp0EKBFfxt"
      },
      "outputs": [],
      "source": [
        "example_data_layout = dtensor.Layout(['batch', dtensor.UNSHARDED], mesh)  # or\n",
        "example_data_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-6n0DericV"
      },
      "source": [
        "## Criação de camadas do Keras com layout\n",
        "\n",
        "No esquema Paralelo de Dados, costuma-se criar os pesos do modelo com um layout completamente replicado para que cada réplica do modelo possa fazer cálculos com os dados de entrada fragmentados.\n",
        "\n",
        "Para configurar as informações do layout para seus pesos de camadas, o Keras expôs um parâmetro extra no construtor de camadas para a maioria das camadas integradas.\n",
        "\n",
        "O seguinte exemplo cria um pequeno modelo de classificação de imagens com layout de pesos completamente replicado. Você pode especificar as informações de layout `kernel` e `bias` em `tf.keras.layers.Dense` por meio dos argumentos `kernel_layout` e `bias_layout`. A maioria das camadas integradas do Keras estão prontas para especificação explícita do `Layout` para os pesos das camadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Koc5GlA1tFXY"
      },
      "outputs": [],
      "source": [
        "unsharded_layout_2d = dtensor.Layout.replicated(mesh, 2)\n",
        "unsharded_layout_1d = dtensor.Layout.replicated(mesh, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfOGTIxGs5Ql"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, \n",
        "                        activation='relu',\n",
        "                        name='d1',\n",
        "                        kernel_layout=unsharded_layout_2d, \n",
        "                        bias_layout=unsharded_layout_1d),\n",
        "  tf.keras.layers.Dense(10,\n",
        "                        name='d2',\n",
        "                        kernel_layout=unsharded_layout_2d, \n",
        "                        bias_layout=unsharded_layout_1d)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frf3jsVtx_n"
      },
      "source": [
        "Você pode verificar as informações do layout analisando a propriedade `layout` dos pesos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_nqv_VdwcXo"
      },
      "outputs": [],
      "source": [
        "for weight in model.weights:\n",
        "  print(f'Weight name: {weight.name} with layout: {weight.layout}')\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FMGB-QsxPtU"
      },
      "source": [
        "## Carregamento de um dataset e criação de um pipeline de entrada\n",
        "\n",
        "Carregue um dataset MNIST e configure um pipeline de entrada de pré-processamento para ele. O dataset em si não está associado a qualquer informação de layout do DTensor. Há planos para melhorar a integração do DTensor para Keras com o `tf.data` em versões futuras do TensorFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGt4kwltxOt4"
      },
      "outputs": [],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkUaOB_ryaLH"
      },
      "outputs": [],
      "source": [
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efm2H1iqydan"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcrg6QAtyis4"
      },
      "outputs": [],
      "source": [
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHEZwib7lhqn"
      },
      "source": [
        "## Definição da lógica de treinamento do modelo\n",
        "\n",
        "Agora defina a lógica de treinamento e avaliação do modelo.\n",
        "\n",
        "A partir do TensorFlow 2.9, você precisa escrever um loop de treinamento personalizado para um modelo do Keras com DTensor. Isso é feito para adicionar informações de layout adequadas nos dados de entrada, o que não está integrado às funções padrão `tf.keras.Model.fit()` ou `tf.keras.Model.eval()` do Keras. Haverá mais suporte ao `tf.data` em uma versão futura. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAx11gMjzzjs"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x, y, optimizer, metrics):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x, training=True)\n",
        "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
        "    # global loss (scalar).\n",
        "    loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y, logits, from_logits=True))\n",
        "    \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  for metric in metrics.values():\n",
        "    metric.update_state(y_true=y, y_pred=logits)\n",
        "\n",
        "  loss_per_sample = loss / len(x)\n",
        "  results = {'loss': loss_per_sample}\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maSTWeRemO0P"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def eval_step(model, x, y, metrics):\n",
        "  logits = model(x, training=False)\n",
        "  loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
        "        y, logits, from_logits=True))\n",
        "\n",
        "  for metric in metrics.values():\n",
        "    metric.update_state(y_true=y, y_pred=logits)\n",
        "\n",
        "  loss_per_sample = loss / len(x)\n",
        "  results = {'eval_loss': loss_per_sample}\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt00axcLmvLr"
      },
      "outputs": [],
      "source": [
        "def pack_dtensor_inputs(images, labels, image_layout, label_layout):\n",
        "  num_local_devices = image_layout.mesh.num_local_devices()\n",
        "  images = tf.split(images, num_local_devices)\n",
        "  labels = tf.split(labels, num_local_devices)\n",
        "  images = dtensor.pack(images, image_layout)\n",
        "  labels = dtensor.pack(labels, label_layout)\n",
        "  return  images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eb-qIJGrxB9"
      },
      "source": [
        "## Métricas e otimizadores\n",
        "\n",
        "Ao usar a API do DTensor com `Metric` e `Optimizer` do Keras, você precisará fornecer as informações de malha extras para que qualquer variável de estado e tensor internos funcionem com as variáveis do modelo.\n",
        "\n",
        "- Para um otimizador, o DTensor tem um novo namespace experimental, o `keras.dtensor.experimental.optimizers`, em que muitos Otimizadores existentes no Keras são expandidos para receberem um argumento de `mesh` adicional. Em versões futuras, isso poderá ser combinado com os otimizadores principais do Keras.\n",
        "\n",
        "- Para as métricas, você pode especificar a `mesh` diretamente para o construtor como argumento para torná-la uma `Metric` compatível com o DTensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lu_0mz1sxrl"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.dtensor.experimental.optimizers.Adam(0.01, mesh=mesh)\n",
        "metrics = {'accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}\n",
        "eval_metrics = {'eval_accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzufrkistELx"
      },
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "O exemplo abaixo fragmenta os dados do pipeline de entrada na dimensão do lote e treina o modelo, que tem pesos completamente replicados.\n",
        "\n",
        "Com 3 épocas, o modelo deve atingir uma exatidão de cerca de 97%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZW568Dk0vvL"
      },
      "outputs": [],
      "source": [
        "num_epochs = 3\n",
        "\n",
        "image_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=4)\n",
        "label_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"============================\") \n",
        "  print(\"Epoch: \", epoch)\n",
        "  for metric in metrics.values():\n",
        "    metric.reset_state()\n",
        "  step = 0\n",
        "  results = {}\n",
        "  pbar = tf.keras.utils.Progbar(target=None, stateful_metrics=[])\n",
        "  for input in ds_train:\n",
        "    images, labels = input[0], input[1]\n",
        "    images, labels = pack_dtensor_inputs(\n",
        "        images, labels, image_layout, label_layout)\n",
        "\n",
        "    results.update(train_step(model, images, labels, optimizer, metrics))\n",
        "    for metric_name, metric in metrics.items():\n",
        "      results[metric_name] = metric.result()\n",
        "\n",
        "    pbar.update(step, values=results.items(), finalize=False)\n",
        "    step += 1\n",
        "  pbar.update(step, values=results.items(), finalize=True)\n",
        "\n",
        "  for metric in eval_metrics.values():\n",
        "    metric.reset_state()\n",
        "  for input in ds_test:\n",
        "    images, labels = input[0], input[1]\n",
        "    images, labels = pack_dtensor_inputs(\n",
        "        images, labels, image_layout, label_layout)\n",
        "    results.update(eval_step(model, images, labels, eval_metrics))\n",
        "\n",
        "  for metric_name, metric in eval_metrics.items():\n",
        "    results[metric_name] = metric.result()\n",
        "  \n",
        "  for metric_name, metric in results.items():\n",
        "    print(f\"{metric_name}: {metric.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEXF6qCuoSr"
      },
      "source": [
        "## Especificação do Layout para o código existente do modelo\n",
        "\n",
        "Às vezes, você terá modelos que funcionam bem para seu caso de uso. A especificação de informações de `Layout` em cada camada individual do modelo demanda muito trabalho, exigindo muitas alterações.\n",
        "\n",
        "Para ajudar a converter facilmente seu modelo atual do Keras para que ele funcione com a API do DTensor, você pode usar a nova API `dtensor.LayoutMap`, que permite especificar o `Layout` globalmente.\n",
        "\n",
        "Primeiro, você precisa criar uma instância de `LayoutMap`, que é um objeto tipo dicionário contendo todo o `Layout` que você gostaria de especificar para os pesos do seu modelo.\n",
        "\n",
        "O `LayoutMap` precisa de uma instância de `Mesh` na inicialização, que pode ser usada para fornecer o `Layout` replicado padrão para qualquer peso que não tenha o Layout configurado. Caso você queira que todos os pesos do seu modelo sejam somente replicados completamente, pode fornecer um `LayoutMap` vazio, e a malha padrão será usada para criar o `Layout` replicado.\n",
        "\n",
        "O `LayoutMap` usa uma string como chave e um `Layout` como valor. Existe uma diferença de comportamento entre um dicionário Python comum e esta classe. A chave da string será tratada como uma expressão regular ao recuperar o valor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCq5Nl-UP_dS"
      },
      "source": [
        "### Modelo com subclasses\n",
        "\n",
        "Considere o seguinte modelo, definido usando-se a sintaxe de modelo de subclasse do Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ0hRFs8unu0"
      },
      "outputs": [],
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, name=None):\n",
        "    super().__init__(name=name)\n",
        "    self.feature = tf.keras.layers.Dense(16)\n",
        "    self.feature_2 = tf.keras.layers.Dense(24)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    x = self.feature(inputs)\n",
        "    x = self.dropout(x, training=training)\n",
        "    return self.feature_2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1njxqPB-yS97"
      },
      "source": [
        "Há 4 pesos neste modelo, que são `kernel` e `bias` para duas camadas `Dense`. Cada um deles é mapeado com base no caminho do objeto:\n",
        "\n",
        "- `model.feature.kernel`\n",
        "- `model.feature.bias`\n",
        "- `model.feature_2.kernel`\n",
        "- `model.feature_2.bias`\n",
        "\n",
        "Observação: para modelos com subclasse, o atributo name, em vez do atributo `.name` da camada, é usado como a chave para recuperar o Layout no mapeamento. Isso é consistente com a conversão seguida pelos checkpoints do `tf.Module`. Para modelos complexos com mais do que poucas camadas, você pode [inspecionar manualmente os checkpoints](https://www.tensorflow.org/guide/checkpoint#manually_inspecting_checkpoints) para ver os mapeamentos de atributos.\n",
        "\n",
        "Agora, defina o seguinte `LayoutMap` e aplique-o ao modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goVX6iIZw468"
      },
      "outputs": [],
      "source": [
        "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
        "\n",
        "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
        "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
        "\n",
        "with layout_map.scope():\n",
        "  subclassed_model = SubclassedModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M32HcSp_PyWs"
      },
      "source": [
        "Os pesos do modelo são criados na primeira chamada, então faça uma chamada ao modelo com uma entrada do DTensor e confirme que os pesos tenham os layouts esperados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3CbD9l7qUNq"
      },
      "outputs": [],
      "source": [
        "dtensor_input = dtensor.copy_to_mesh(tf.zeros((16, 16)), layout=unsharded_layout_2d)\n",
        "# Trigger the weights creation for subclass model\n",
        "subclassed_model(dtensor_input)\n",
        "\n",
        "print(subclassed_model.feature.kernel.layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyCnfd-4Q2jk"
      },
      "source": [
        "Dessa forma, você pode mapear o `Layout` para seus modelos rapidamente, sem atualizar o código existente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GliUdWTQnKC"
      },
      "source": [
        "### Modelos sequencial e funcional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zzvTqAR2Teu"
      },
      "source": [
        "Para os modelos sequencial e funcional do Keras, você também pode usar o `LayoutMap`.\n",
        "\n",
        "Observação: para os modelos funcional e sequencial, os mapeamentos são um pouco diferentes. As camadas do modelo não têm um atributo público vinculado ao modelo (embora você possa acessá-las por `model.layers` como uma lista). Nesse caso, use o nome da string como a chave. O nome da string sempre será único em um modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXK2EquIRJCC"
      },
      "outputs": [],
      "source": [
        "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
        "\n",
        "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
        "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBzwJqrg2TH3"
      },
      "outputs": [],
      "source": [
        "with layout_map.scope():\n",
        "  inputs = tf.keras.Input((16,), batch_size=16)\n",
        "  x = tf.keras.layers.Dense(16, name='feature')(inputs)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "  output = tf.keras.layers.Dense(32, name='feature_2')(x)\n",
        "  model = tf.keras.Model(inputs, output)\n",
        "\n",
        "print(model.layers[1].kernel.layout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPuh1NlE3-wO"
      },
      "outputs": [],
      "source": [
        "with layout_map.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(16, name='feature', input_shape=(16,)),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Dense(32, name='feature_2')\n",
        "  ])\n",
        "\n",
        "print(model.layers[2].kernel.layout)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "dtensor_keras_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
