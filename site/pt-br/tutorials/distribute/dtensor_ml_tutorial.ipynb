{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "# Treinamento distribuído com DTensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6P32iYYV27b"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver em TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Executar no Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/pt-br/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fonte no GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/pt-br/tutorials/distribute/dtensor_ml_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Baixar notebook</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiF4jjX4O1mF"
      },
      "source": [
        "## Visão geral\n",
        "\n",
        "O DTensor oferece uma maneira de distribuir o treinamento do seu modelo nos dispositivos para aumentar a eficiência, confiabilidade e escalabilidade. Confira mais detalhes sobre os conceitos do DTensor no [Guia de programação do DTensor](https://www.tensorflow.org/guide/dtensor_overview).\n",
        "\n",
        "Neste tutorial, você treinará um modelo de Análise de Sentimentos com o DTensor. Três esquemas de treinamento distribuído são demonstrados neste exemplo:\n",
        "\n",
        "- Treinamento Paralelo de Dados, em que as amostras do treinamento são fragmentadas (particionadas) nos dispositivos.\n",
        "- Treinamento Paralelo de Modelo, em que as variáveis do modelo são fragmentadas nos dispositivos.\n",
        "- Treinamento Paralelo Espacial, em que as características dos dados de entrada são fragmentadas nos dispositivos. (Também conhecido como [Particionamento Espacial](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus))\n",
        "\n",
        "A parte de treinamento deste tutorial foi inspirada no notebook [Guia do Kaggle sobre Análise de Sentimentos](https://www.kaggle.com/code/anasofiauzsoy/yelp-review-sentiment-analysis-tensorflow-tfds/notebook). Para entender todo o fluxo de trabalho de treinamento e avaliação (sem o DTensor), confira esse notebook.\n",
        "\n",
        "Veja abaixo as etapas deste tutorial:\n",
        "\n",
        "- Primeiro comece com uma limpeza de dados para obter um `tf.data.Dataset` de frases divididas em tokens e sua polaridade.\n",
        "\n",
        "- Em seguida, crie um modelo MLP com camadas Dense e BatchNorm personalizadas. Use um `tf.Module` para monitorar as variáveis de inferência. O construtor do modelo recebe argumentos `Layout` adicionais para controlar a fragmentação das variáveis.\n",
        "\n",
        "- Para o treinamento, primeiro você usa o treinamento Paralelo de Dados junto com o recurso de checkpoint do `tf.experimental.dtensor`. Em seguida, você prossegue para o treinamento Paralelo de Modelo e o treinamento Paralelo Espacial.\n",
        "\n",
        "- A seção final descreve brevemente a interação entre `tf.saved_model` e `tf.experimental.dtensor` (a partir do TensorFlow 2.9).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD80veeg7QtW"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "O DTensor faz parte da versão 2.9.0 do TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RKXLJN-7Yyb"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade --pre tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcxP4_Zu7ciQ"
      },
      "source": [
        "Em seguida, importe `tensorflow` e `tensorflow.experimental.dtensor`. Depois, configure o TensorFlow para usar 8 CPUs virtuais.\n",
        "\n",
        "Embora este exemplo use CPUs, o DTensor funciona da mesma forma em dispositivos com CPU, GPU ou TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXcB26oP7dUd"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.experimental import dtensor\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHtO6MJLUXlz"
      },
      "outputs": [],
      "source": [
        "def configure_virtual_cpus(ncpu):\n",
        "  phy_devices = tf.config.list_physical_devices('CPU')\n",
        "  tf.config.set_logical_device_configuration(phy_devices[0], [\n",
        "        tf.config.LogicalDeviceConfiguration(),\n",
        "    ] * ncpu)\n",
        "\n",
        "configure_virtual_cpus(8)\n",
        "DEVICES = [f'CPU:{i}' for i in range(8)]\n",
        "\n",
        "tf.config.list_logical_devices('CPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omYd4jbF7j_I"
      },
      "source": [
        "## Download do dataset\n",
        "\n",
        "Baixe o conjunto de dados de avaliações do IMDB para treinar o modelo de Análise de Sentimentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW4w4QlFVHhx"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('imdb_reviews', split='train', shuffle_files=True, batch_size=64)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki3mpfi4aZH8"
      },
      "source": [
        "## Preparação dos dados\n",
        "\n",
        "Primeiro, divida o texto em tokens. Use uma extensão do one-hot encoding, o modo `“td_idf”` de `tf.keras.layers.TextVectorization`.\n",
        "\n",
        "-     Por questões de velocidade, limite o número de tokens a 1.200.\n",
        "- Para manter o `tf.Module` simples, execute `TextVectorization` em uma etapa de pré-processamento antes do treinamento.\n",
        "\n",
        "O resultado final da seção de limpeza de dados é um `Dataset` com o texto dividido em tokens como `x` e o rótulo como `y`.\n",
        "\n",
        "**Observação**: executar o `TextVectorization` em uma etapa de pré-processamento **não é uma prática comum nem recomendada**, pois, ao fazer isso, pressupõe-se que os dados de treinamento caibam na memória do cliente, o que nem sempre é o caso.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNpxjku_57Lg"
      },
      "outputs": [],
      "source": [
        "text_vectorization = tf.keras.layers.TextVectorization(output_mode='tf_idf', max_tokens=1200, output_sequence_length=None)\n",
        "text_vectorization.adapt(data=train_data.map(lambda x: x['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q16bjngoVwQp"
      },
      "outputs": [],
      "source": [
        "def vectorize(features):\n",
        "  return text_vectorization(features['text']), features['label']\n",
        "\n",
        "train_data_vec = train_data.map(vectorize)\n",
        "train_data_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atTqL9kE5wz4"
      },
      "source": [
        "## Criação de uma rede neural com o DTensor\n",
        "\n",
        "Agora, crie um uma rede Multi-Layer Perceptron (MLP) com o `DTensor`. A rede usará camadas Dense e BatchNorm totalmente conectadas.\n",
        "\n",
        "O `DTensor` expande o TensorFlow por meio de uma expansão de SPMD (Single-Program Multi-Data – um programa, múltiplos dados) do TensorFlow Ops comum de acordo com os atributos `dtensor.Layout` do `Tensor` e das variáveis de entrada.\n",
        "\n",
        "As variáveis das camadas com reconhecimento do `DTensor` são `dtensor.DVariable`, e os construtores de objetos de camadas com reconhecimento do `DTensor` recebem outras entradas `Layout` além dos parâmetros de camada usuais.\n",
        "\n",
        "Observação: a partir do TensorFlow 2.9, as camadas do Keras, como `tf.keras.layer.Dense`, e `tf.keras.layer.BatchNormalization`, aceitam argumentos `dtensor.Layout`.  Consulte o [Tutorial de integração do Keras com o DTensor](/tutorials/distribute/dtensor_keras_tutorial) para ver mais informações sobre como usar o Keras com o DTensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMCt-Gj3b3Jy"
      },
      "source": [
        "### Camada Dense\n",
        "\n",
        "A seguinte camada Dense personalizada define 2 variáveis de camada: $W_{ij}$ é a variável para os pesos, e $b_i$ é a variável para os bias.\n",
        "\n",
        "$$ y_j = \\sigma(\\sum_i x_i W_{ij} + b_j) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlFUJWNjl4N"
      },
      "source": [
        "### Dedução do Layout\n",
        "\n",
        "Este resultado advém das seguintes observações:\n",
        "\n",
        "- A fragmentação DTensor preferida para operandos do produto escalar de uma matriz $t_j = \\sum_i x_i W_{ij}$ é a fragmentação de $\\mathbf{W}$ e $\\mathbf{x}$ da mesma forma no eixo $i$.\n",
        "\n",
        "- A fragmentação DTensor preferida para operandos da soma de uma matriz $t_j + b_j$ é a fragmentação de $\\mathbf{t}$ e $\\mathbf{b}$ da mesma forma no eixo $j$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpKblz7Yb16G"
      },
      "outputs": [],
      "source": [
        "class Dense(tf.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size,\n",
        "               init_seed, weight_layout, activation=None):\n",
        "    super().__init__()\n",
        "\n",
        "    random_normal_initializer = tf.function(tf.random.stateless_normal)\n",
        "\n",
        "    self.weight = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(\n",
        "            random_normal_initializer, weight_layout,\n",
        "            shape=[input_size, output_size],\n",
        "            seed=init_seed\n",
        "            ))\n",
        "    if activation is None:\n",
        "      activation = lambda x:x\n",
        "    self.activation = activation\n",
        "    \n",
        "    # bias is sharded the same way as the last axis of weight.\n",
        "    bias_layout = weight_layout.delete([0])\n",
        "\n",
        "    self.bias = dtensor.DVariable(\n",
        "        dtensor.call_with_layout(tf.zeros, bias_layout, [output_size]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = tf.matmul(x, self.weight) + self.bias\n",
        "    y = self.activation(y)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfVY_vAKbxM0"
      },
      "source": [
        "### BatchNorm\n",
        "\n",
        "Uma camada de normalização de lotes ajuda a evitar o colapso de modos durante o treinamento. Neste caso, a inclusão de camadas de normalização de lotes ajuda que o treinamento do modelo evite gerar um modelo que produza somente zeros.\n",
        "\n",
        "O construtor da camada `BatchNorm` personalizada abaixo não recebe um argumento `Layout`. O motivo é que `BatchNorm` não tem variáveis de camada. Isso ainda funciona com o DTensor porque “x”, a única entrada da camada, já é um DTensor que representa o lote global.\n",
        "\n",
        "Observação: com o DTensor, o Tensor de entrada “x” sempre representa o lote global. Portanto, `tf.nn.batch_normalization` é aplicado ao lote global. Isso é diferente do treinamento com `tf.distribute.MirroredStrategy`, em que o Tensor “x” representa somente o fragmento por réplica do lote (o lote local)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riBA9pfhlPFq"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(tf.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def __call__(self, x, training=True):\n",
        "    if not training:\n",
        "      # This branch is not used in the Tutorial.\n",
        "      pass\n",
        "    mean, variance = tf.nn.moments(x, axes=[0])\n",
        "    return tf.nn.batch_normalization(x, mean, variance, 0.0, 1.0, 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4R4MPz5prh4"
      },
      "source": [
        "Uma camada de normalização de lotes completa (como `tf.keras.layers.BatchNormalization`) precisará de argumentos Layout para suas variáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unFcP99zprJj"
      },
      "outputs": [],
      "source": [
        "def make_keras_bn(bn_layout):\n",
        "  return tf.keras.layers.BatchNormalization(gamma_layout=bn_layout,\n",
        "                                            beta_layout=bn_layout,\n",
        "                                            moving_mean_layout=bn_layout,\n",
        "                                            moving_variance_layout=bn_layout,\n",
        "                                            fused=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Dj7AJ_lPs0"
      },
      "source": [
        "### Junção das camadas\n",
        "\n",
        "Em seguida, crie uma rede Multi-Layer Perceptron (MLP) com os blocos acima.  O diagrama abaixo mostra as relações dos eixos entre a entrada `x` e as matrizes de peso para as duas camadas `Dense` sem qualquer fragmentação ou replicação DTensor aplicada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udFGAO-NrZw6"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/dtensor/no_dtensor.png\" class=\"no-filter\" alt=\"The input and weight matrices for a non distributed model.\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DCQ0aQ5rQtB"
      },
      "source": [
        "A saída da primeira camada `Dense` é passada para a entrada da segunda camada `Dense` (após o `BatchNorm`). Portanto, a fragmentação DTensor preferida para a saída da primeira camada `Dense` ($\\mathbf{W_1}$) e para a entrada da segunda camada `Dense` ($\\mathbf{W_2}$) é a fragmentação de $\\mathbf{W_1}$ e $\\mathbf{W_2}$ da mesma forma no eixo comum $\\hat{j}$.\n",
        "\n",
        "$$ \\mathsf{Layout}[{W_{1,ij}}; i, j] = \\left[\\hat{i}, \\hat{j}\\right] \\ \\mathsf{Layout}[{W_{2,jk}}; j, k] = \\left[\\hat{j}, \\hat{k} \\right] $$\n",
        "\n",
        "Embora a dedução do layout mostre que os 2 layouts não são independentes, para fins de simplicidade da interface do modelo, `MLP` receberá 2 argumentos `Layout`, um por camada Dense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "junyS-965opl"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "class MLP(tf.Module):\n",
        "\n",
        "  def __init__(self, dense_layouts: Tuple[dtensor.Layout, dtensor.Layout]):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dense_layouts[0], activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dense_layouts[1])\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dgLmebHhr7h"
      },
      "source": [
        "O equilíbrio entre a precisão das restrições de dedução de layout e a simplicidade da API é uma questão comum de design de APIs que usam o DTensor. Também é possível capturar a dependência entre os `Layouts` com uma API diferente. Por exemplo, a classe `MLPStricter` cria objetos `Layout` no construtor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZR7UlihsYX"
      },
      "outputs": [],
      "source": [
        "class MLPStricter(tf.Module):\n",
        "\n",
        "  def __init__(self, mesh, input_mesh_dim, inner_mesh_dim1, output_mesh_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dense1 = Dense(\n",
        "        1200, 48, (1, 2), dtensor.Layout([input_mesh_dim, inner_mesh_dim1], mesh),\n",
        "        activation=tf.nn.relu)\n",
        "    self.bn = BatchNorm()\n",
        "    self.dense2 = Dense(48, 2, (3, 4), dtensor.Layout([inner_mesh_dim1, output_mesh_dim], mesh))\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    y = x\n",
        "    y = self.dense1(y)\n",
        "    y = self.bn(y)\n",
        "    y = self.dense2(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcQi7D5mal2L"
      },
      "source": [
        "Para garantir que o modelo seja executado, coloque em seu modelo layouts completamente replicados e um lote completamente replicado de entrada `“x”`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPuYeQwallh"
      },
      "outputs": [],
      "source": [
        "WORLD = dtensor.create_mesh([(\"world\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout.replicated(WORLD, rank=2),\n",
        "             dtensor.Layout.replicated(WORLD, rank=2)])\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x = dtensor.copy_to_mesh(sample_x, dtensor.Layout.replicated(WORLD, rank=2))\n",
        "print(model(sample_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akrjDstEpDv9"
      },
      "source": [
        "## Movimentação dos dados para o dispositivo\n",
        "\n",
        "Geralmente, iteradores `tf.data` (e os outros métodos de busca de dados) produzem objetos tensor armazenados na memória local do dispositivo host. Esses dados precisam ser transferidos para a memória do dispositivo acelerador que armazena tensores do DTensor.\n",
        "\n",
        "`dtensor.copy_to_mesh` não é apropriado para essa situação, pois replica tensores de entrada em todos os dispositivos devido à perspectiva global do DTensor. Portanto, neste tutorial, você usará uma função helper `repack_local_tensor` para permitir a transferência dos dados. A função helper usa o `dtensor.pack` para enviar (e somente enviar) o fragmento do lote global que é destinado a uma réplica para o dispositivo que armazena a réplica.\n",
        "\n",
        "Esta função simplificada pressupõe um único cliente. Em uma aplicação multicliente, pode ser trabalhoso determinar a forma correta de dividir o tensor local e o mapeamento entre os segmentos da divisão e os dispositivos locais.\n",
        "\n",
        "Está planejada uma API DTensor adicional para simplificar a integração com `tf.data` , com suporte a aplicações com um e vários clientes. Fique de olho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t5WvQR4Hvo4"
      },
      "outputs": [],
      "source": [
        "def repack_local_tensor(x, layout):\n",
        "  \"\"\"Repacks a local Tensor-like to a DTensor with layout.\n",
        "\n",
        "  This function assumes a single-client application.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x)\n",
        "  sharded_dims = []\n",
        "\n",
        "  # For every sharded dimension, use tf.split to split the along the dimension.\n",
        "  # The result is a nested list of split-tensors in queue[0].\n",
        "  queue = [x]\n",
        "  for axis, dim in enumerate(layout.sharding_specs):\n",
        "    if dim == dtensor.UNSHARDED:\n",
        "      continue\n",
        "    num_splits = layout.shape[axis]\n",
        "    queue = tf.nest.map_structure(lambda x: tf.split(x, num_splits, axis=axis), queue)\n",
        "    sharded_dims.append(dim)\n",
        "\n",
        "  # Now we can build the list of component tensors by looking up the location in\n",
        "  # the nested list of split-tensors created in queue[0].\n",
        "  components = []\n",
        "  for locations in layout.mesh.local_device_locations():\n",
        "    t = queue[0]\n",
        "    for dim in sharded_dims:\n",
        "      split_index = locations[dim]  # Only valid on single-client mesh.\n",
        "      t = t[split_index]\n",
        "    components.append(t)\n",
        "\n",
        "  return dtensor.pack(components, layout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KKCDcjG7zj2"
      },
      "source": [
        "## Treinamento Paralelo de Dados\n",
        "\n",
        "Nesta seção, você treinará seu modelo MLP com dados do treinamento Paralelo de Dados. Seções posteriores demonstrarão os treinamentos Paralelo de Modelo e Paralelo Espacial.\n",
        "\n",
        "O treinamento Paralelo de Dados é um esquema usado com frequência para aprendizado de máquina distribuído:\n",
        "\n",
        "- As variáveis do modelo são replicadas em N dispositivos.\n",
        "- Um lote global é dividido em N lotes por réplica.\n",
        "- Cada lote por réplica é treinado no dispositivo da réplica.\n",
        "- O gradiente é reduzido antes de os dados de peso serem aplicados coletivamente em todas as réplicas.\n",
        "\n",
        "O treinamento Paralelo de Dados proporciona um speedup praticamente linear quanto ao número de dispositivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMsLUyTGq3oL"
      },
      "source": [
        "### Criação de uma malha para paralelismo de dados\n",
        "\n",
        "Um loop de treinamento típico de Paralelo de Dados usa uma `Mesh` DTensor que consiste de uma única dimensão `batch`, em que cada dispositivo se torna uma réplica que recebe um fragmento do lote global.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_data_para.png\" class=\"no-filter\" alt=\"Data parallel mesh\">\n",
        "\n",
        "O modelo replicado é executado na réplica e, portanto, as variáveis do modelo são completamente replicadas (não fragmentadas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0IyOlxmeu4I"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=DEVICES)\n",
        "\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),\n",
        "             dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh),])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OREKwBybo1gZ"
      },
      "source": [
        "### Encapsulamento dos dados de treinamento em DTensors\n",
        "\n",
        "O lote de dados de treinamento deve ser encapsulado em DTensors fragmentados no eixo de `“batch”`(primeiro) para que o DTensor distribua os dados de treinamento na dimensão de malha do `“batch”` de maneira uniforme.\n",
        "\n",
        "**Observação:** no DTensor, o `batch size` sempre se refere ao tamanho global de lote. O tamanho do lote deve ser escolhido de uma forma que possa ser dividido pelo tamanho da dimensão de malha do `batch`, gerando um número inteiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xMYkTpGocY8"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y\n",
        "\n",
        "sample_x, sample_y = train_data_vec.take(1).get_single_element()\n",
        "sample_x, sample_y = repack_batch(sample_x, sample_y, mesh)\n",
        "\n",
        "print('x', sample_x[:, 0])\n",
        "print('y', sample_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uONSiqOIkFL1"
      },
      "source": [
        "### Etapa de treinamento\n",
        "\n",
        "Este exemplo usa um otimizador do Método do Gradiente Descendente Estocástico com um Loop de Treinamento Personalizado (CTL, na sigla em inglês). Confira o [guia de Loop de Treinamento Personalizado](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) e o [Passo a passo](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough) para ver mais informações sobre esses tópicos.\n",
        "\n",
        "O `train_step` é encapsulado como uma `tf.function` para indicar que esse corpo precisa ser traçado como um Grafo TensorFlow. O corpo de `train_step` consiste de um passo de inferência para frente, um passo de gradiente para trás e a atualização das variáveis.\n",
        "\n",
        "O corpo de `train_step` não contém nenhuma anotação DTensor especial. Em vez disso, `train_step` contém somente operações TensorFlow de alto nível que processam a entrada `x` e `y` da visão global do lote de entrada e o modelo. Todas as anotações do DTensor (`Mesh`, `Layout`) são contabilizadas fora do passo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwUFzLGDtQT6"
      },
      "outputs": [],
      "source": [
        "# Refer to the CTL (custom training loop guide)\n",
        "@tf.function\n",
        "def train_step(model, x, y, learning_rate=tf.constant(1e-4)):\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
        "    # global loss (scalar).\n",
        "    loss = tf.reduce_sum(\n",
        "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=y))\n",
        "  parameters = model.trainable_variables\n",
        "  gradients = tape.gradient(loss, parameters)\n",
        "  for parameter, parameter_gradient in zip(parameters, gradients):\n",
        "    parameter.assign_sub(learning_rate * parameter_gradient)\n",
        "\n",
        "  # Define some metrics\n",
        "  accuracy = 1.0 - tf.reduce_sum(tf.cast(tf.argmax(logits, axis=-1, output_type=tf.int64) != y, tf.float32)) / x.shape[0]\n",
        "  loss_per_sample = loss / len(x)\n",
        "  return {'loss': loss_per_sample, 'accuracy': accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OYTu4j0evWT"
      },
      "source": [
        "### Criação de checkpoints\n",
        "\n",
        "Você pode criar um checkpoint de um modelo DTensor usando `tf.train.Checkpoint`. Ao salvar e restaurar DVariables fragmentadas, será feito um processo fragmentado eficiente de salvamento e restauração. Atualmente, ao usar `tf.train.Checkpoint.save` e `tf.train.Checkpoint.restore`, todas as DVariables devem estar na mesma malha de host, e DVariables e variáveis não podem ser salvas juntas. Saiba mais sobre a criação de checkpoints [neste guia](../../guide/checkpoint.ipynb).\n",
        "\n",
        "Quando um checkpoint DTensor é restaurado, os `Layout`s de variáveis podem ser diferentes em relação a quando o checkpoint foi salvo. Ou seja, salvar modelos DTensor é independente de malhas e layouts, afetando somente a eficiência do salvamento fragmentado. Você pode salvar um modelo DTensor com uma determinada malha e layout e restaurá-lo em uma malha e layout diferentes. Este tutorial usa esse recurso para continuar o treinamento nas seções Treinamento Paralelo de Modelo e Treinamento Paralelo Espacial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsInFFJg7x9t"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = tempfile.mkdtemp()\n",
        "\n",
        "def start_checkpoint_manager(model):\n",
        "  ckpt = tf.train.Checkpoint(root=model)\n",
        "  manager = tf.train.CheckpointManager(ckpt, CHECKPOINT_DIR, max_to_keep=3)\n",
        "\n",
        "  if manager.latest_checkpoint:\n",
        "    print(\"Restoring a checkpoint\")\n",
        "    ckpt.restore(manager.latest_checkpoint).assert_consumed()\n",
        "  else:\n",
        "    print(\"New training\")\n",
        "  return manager\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r77ky5Jgp1j"
      },
      "source": [
        "### Loop de treinamento\n",
        "\n",
        "Para o esquema do treinamento Paralelo de Dados, utilize épocas e gere relatórios do progresso. Três épocas não são suficientes para treinar o modelo – uma precisão de 50% é tão boa quanto tentar adivinhar aleatoriamente.\n",
        "\n",
        "Ative os checkpoints para que você possa continuar o treinamento posteriormente. Na próxima seção, você carregará um checkpoint e fará o treinamento com um esquema paralelo diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaLn-vGZgqbS"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()), stateful_metrics=[])\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFJEhum7EGD"
      },
      "source": [
        "## Treinamento Paralelo de Modelo\n",
        "\n",
        "Se você mudar para uma `Mesh` bidimensional e fragmentar as variáveis do modelo na segunda dimensão da malha, então o treinamento vira um Paralelo de Modelo.\n",
        "\n",
        "No treinamento Paralelo de Modelo, cada réplica do modelo fica em diversos dispositivos (2, neste caso):\n",
        "\n",
        "- Há 4 réplicas do modelo, e o lote de dados de treinamento é distribuído para as 4 réplicas.\n",
        "- Os 2 dispositivos dentro de uma única réplica do modelo recebem os dados de treinamento replicados.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_model_para.png\" class=\"no-filter\" alt=\"Model parallel mesh\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gZE9IT5Dzwl"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 4), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([dtensor.UNSHARDED, \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihof3DkMFKnf"
      },
      "source": [
        "Como os dados de treinamento ainda são fragmentados na dimensão do lote, você pode reutilizar a mesma função `repack_batch` usada no caso do treinamento Paralelo de Dados. O DTensor vai replicar automaticamente o lote por réplica em todos os dispositivos dentro da réplica na dimensão de malha `\"model\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZf56ynbE_p1"
      },
      "outputs": [],
      "source": [
        "def repack_batch(x, y, mesh):\n",
        "  x = repack_local_tensor(x, layout=dtensor.Layout(['batch', dtensor.UNSHARDED], mesh))\n",
        "  y = repack_local_tensor(y, layout=dtensor.Layout(['batch'], mesh))\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW3OXdhNFfpv"
      },
      "source": [
        "Em seguida, execute o loop de treinamento. O loop de treinamento reutiliza o mesmo gerenciador de checkpoints usado no exemplo do treinamento Paralelo de Dados, e o código é idêntico.\n",
        "\n",
        "Você pode continuar treinando o modelo Paralelo de Dados treinado no treinamento Paralelo de Modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLC0wgii7EgA"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "manager = start_checkpoint_manager(model)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "  metrics = {'epoch': epoch}\n",
        "  for x,y in train_data_vec:\n",
        "    x, y = repack_batch(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZH-aMrVzi2L"
      },
      "source": [
        "## Treinamento Paralelo Espacial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-bK6IZ9GCS9"
      },
      "source": [
        "Ao treinar dados com uma dimensionalidade muito alta (por exemplo, uma imagem ou vídeo muito grande), pode ser interessante fragmentar na dimensão de característica. Isso se chama [Particionamento Espacial](https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus), lançado inicialmente no TensorFlow para modelos de treinamento com grandes amostras de entrada 3D.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/dtensor/dtensor_spatial_para.png\" class=\"no-filter\" alt=\"Spatial parallel mesh\">\n",
        "\n",
        "O DTensor também é compatível com esse caso de uso. A única mudança necessária é a criação de uma Malha que inclua uma dimensão de `feature` e a aplicação do `Layout` correspondente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpc9mqURGpmK"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"batch\", 2), (\"feature\", 2), (\"model\", 2)], devices=DEVICES)\n",
        "model = MLP([dtensor.Layout([\"feature\", \"model\"], mesh), \n",
        "             dtensor.Layout([\"model\", dtensor.UNSHARDED], mesh)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i07Wrv-jHBc1"
      },
      "source": [
        "Fragmente os dados de entrada na dimensão de `feature` ao encapsular os tensores de entrada no DTensors. É possível fazer isso com uma função de reencapsulamento ligeiramente diferente, `repack_batch_for_spt`, em que `spt` significa Treinamento Paralelo Espacial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWR8qF6BGtFL"
      },
      "outputs": [],
      "source": [
        "def repack_batch_for_spt(x, y, mesh):\n",
        "    # Shard data on feature dimension, too\n",
        "    x = repack_local_tensor(x, layout=dtensor.Layout([\"batch\", 'feature'], mesh))\n",
        "    y = repack_local_tensor(y, layout=dtensor.Layout([\"batch\"], mesh))\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygl9dqMUHTVN"
      },
      "source": [
        "O Treinamento Paralelo Espacial também pode continuar de um checkpoint criado com outros esquemas de treinamento paralelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3NnpHSKo-hx"
      },
      "outputs": [],
      "source": [
        "num_epochs = 2\n",
        "\n",
        "manager = start_checkpoint_manager(model)\n",
        "for epoch in range(num_epochs):\n",
        "  step = 0\n",
        "  metrics = {'epoch': epoch}\n",
        "  pbar = tf.keras.utils.Progbar(target=int(train_data_vec.cardinality()))\n",
        "\n",
        "  for x, y in train_data_vec:\n",
        "    x, y = repack_batch_for_spt(x, y, mesh)\n",
        "    metrics.update(train_step(model, x, y, 1e-2))\n",
        "\n",
        "    pbar.update(step, values=metrics.items(), finalize=False)\n",
        "    step += 1\n",
        "  manager.save()\n",
        "  pbar.update(step, values=metrics.items(), finalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4L59CpJjYr"
      },
      "source": [
        "## SavedModel e DTensor\n",
        "\n",
        "A integração entre o DTensor e o SavedModel ainda está em desenvolvimento.\n",
        "\n",
        "A partir do TensorFlow `2.11`, `tf.saved_model` pode salvar modelos DTensor fragmentados e replicados e, ao salvar, será feito um salvamento fragmentado eficiente em diferentes dispositivos da malha. Entretanto, após um modelo ser salvo, todas as anotações DTensor são perdidas, e as assinaturas salvas só podem ser usadas com Tensors comuns, não DTensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49HfIq_SJZoj"
      },
      "outputs": [],
      "source": [
        "mesh = dtensor.create_mesh([(\"world\", 1)], devices=DEVICES[:1])\n",
        "mlp = MLP([dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh), \n",
        "           dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)])\n",
        "\n",
        "manager = start_checkpoint_manager(mlp)\n",
        "\n",
        "model_for_saving = tf.keras.Sequential([\n",
        "  text_vectorization,\n",
        "  mlp\n",
        "])\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
        "def run(inputs):\n",
        "  return {'result': model_for_saving(inputs)}\n",
        "\n",
        "tf.saved_model.save(\n",
        "    model_for_saving, \"/tmp/saved_model\",\n",
        "    signatures=run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Csim_VMGxQ"
      },
      "source": [
        "A partir do TensorFlow 2.9.0, você pode fazer uma chamada a uma assinatura carregada somente com um Tensor comum ou um DTensor completamente replicado (que será convertido em um Tensor comum)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG_ASSzR4IWW"
      },
      "outputs": [],
      "source": [
        "sample_batch = train_data.take(1).get_single_element()\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW8yKPrhKQ5b"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(\"/tmp/saved_model\")\n",
        "\n",
        "run_sig = loaded.signatures[\"serving_default\"]\n",
        "result = run_sig(sample_batch['text'])['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GahGbv0ZmkJb"
      },
      "outputs": [],
      "source": [
        "np.mean(tf.argmax(result, axis=-1) == sample_batch['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks-Vs9qsH6jO"
      },
      "source": [
        "## Quais são os próximos passos?\n",
        "\n",
        "Este tutorial demonstrou a criação e o treinamento de um modelo MLP de Análise de Sentimentos com o DTensor.\n",
        "\n",
        "Por meio de primitivos `Mesh` e `Layout`, o DTensor pode transformar uma `tf.function` do TensorFlow em um programa distribuído para diversos esquemas de treinamento.\n",
        "\n",
        "Em uma aplicação de aprendizado de máquina do mundo real, a avaliação e a validação cruzada devem ser usadas para evitar a geração de um modelo sobreajustado. As técnicas apresentadas neste tutorial também podem ser aplicadas para acrescentar paralelismo à avaliação.\n",
        "\n",
        "É muito trabalhoso criar um modelo com `tf.Module` do zero, e reutilizar blocos existentes, como camadas e funções helper, pode acelerar drasticamente o desenvolvimento do modelo. A partir do TensorFlow 2.9, todas as camadas do Keras em `tf.keras.layers` aceitam Layouts do DTensor como argumentos e podem ser usados para criar modelos do DTensor. Você pode até mesmo reutilizar diretamente um modelo do Keras com o DTensor sem modificar a implementação do modelo. Consulte o [Tutorial de integração do Keras com o DTensor](https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial) para ver mais informações sobre como usar o Keras com o DTensor. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dtensor_ml_tutorial.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
